universe = docker
docker_image = pangyuteng/totalsegmentator:latest
docker_pull_policy = always

executable = wasserthal-2022/inference.sh
transfer_input_files = wasserthal-2022/inference.sh,mhd2niigz.py
should_transfer_files = YES
when_to_transfer_output = ON_EXIT

log = log/inference.$(cluster).$(process).log
error = log/inference.$(cluster).$(process).err
output = log/inference.$(cluster).$(process).out

requirements = (OpSys == "LINUX" && Arch == "X86_64" && GPUMEM > 20000 )
request_cpus = 1
request_gpus = 1
request_memory = 10GB
request_disk = 5GB

max_materialize = 10
arguments = "$(myargs)"
queue myargs from wasserthal.args
